
# 7(1)-LLM 과제
### 2021147586 안재후

## 1. Direct Prompting, CoT Prompting, My Prompting 결과 정리
| Method | 0-shot | 3-shot | 5-shot |
| **Direct Prompting** | 0.86 | 0.84 | 0.76 |
| **CoT Prompting** | 0.72 | 0.80 | 0.76 |
| **My Prompting** | 0.70 | 0.68 | 0.82 |

### 결과 분석

## 2. CoT Prompting이 Direct Prompting에 비해 왜 좋을 수 있는지
Chain-of-Thought (CoT) 프롬프팅은 모델이 최종 답변에 도달하기 전에 중간 추론 과정을 생성하도록 유도합니다. 이는 인간이 문제를 해결할 때 문제를 쪼개어 분리해서 생각하는 과정과 유사합니다. 추론 과정을 명시함으로써 모델은 스스로의 논리를 double-check하고 흐름을 유지할 수 있게 합니다. 연산 자원 측면에서는 더 많은 토큰을 생성하게 함으로써, 실질적으로 모델이 문제를 해결하는 데 더 오래 생각할 시간을 주는 효과가 있습니다.

## 3. 본인이 작성한  프롬프트 기법이 CoT에 비해서 왜 더 좋을 수 있는지
제가 제안한 Structured Reasoning 방식은 기존 CoT를 발전시켜, 계획(Plan) 단계와 실행(Solution) 단계를 분리하여 처리하는 방식입니다. 문제를 풀기 위한 추론 과정을 시작하기 전에 무엇을 구해야 하는지 목표(Goal)를 먼저 정의하게 함으로써, 모델이 문제를 정확히 이해했는지 확인하고 방향성을 잡게 합니다. 또한 Goal, Solution, Answer로 과정을 명확히 분리하여 모델이 형식을 준수하게 하고 각 단계에 개별적으로 집중하도록 합니다. 마지막으로 CoT 프롬프팅과 다르게 추론을 진행하면서 계획을 시시각각 수정하지 않고, 먼저 계획을 세우고 그것을 실행하는 과정을 분리합니다. 이에 모델이 맹목적으로 초기 잘못된 계산을 따라가는 것을 방지하고 논리적인 일관성을 유지하도록 합니다.