{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53cd899e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: groq in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (1.0.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (2.4.1)\n",
      "Requirement already satisfied: tqdm in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (4.67.1)\n",
      "Requirement already satisfied: datasets in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (4.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from groq) (4.12.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from groq) (2.12.5)\n",
      "Requirement already satisfied: sniffio in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from groq) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
      "Requirement already satisfied: certifi in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from httpx<1,>=0.23.0->groq) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from pydantic<3,>=1.9.0->groq) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
      "Requirement already satisfied: filelock in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from datasets) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from datasets) (23.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: xxhash in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from datasets) (1.3.4)\n",
      "Requirement already satisfied: packaging in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (0.21.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from requests>=2.32.2->datasets) (2.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (8.3.1)\n",
      "Requirement already satisfied: ipywidgets in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (8.1.8)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from ipywidgets) (9.9.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from ipywidgets) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from ipywidgets) (3.0.16)\n",
      "Requirement already satisfied: decorator>=4.3.2 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in /Users/ilop0/YBIGTA_newbie_assignment/.venv/lib/python3.14/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install groq python-dotenv numpy tqdm datasets\n",
    "!pip install ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "249253df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import random\n",
    "import pprint\n",
    "\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "load_dotenv()\n",
    "random.seed(0)\n",
    "\n",
    "client = Groq()\n",
    "gsm8k_dataset = load_dataset(\"gsm8k\", \"main\")\n",
    "\n",
    "gsm8k_train = gsm8k_dataset[\"train\"]\n",
    "gsm8k_test  = gsm8k_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4d75bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_using_Llama(\n",
    "        prompt: str,\n",
    "        model: str = \"llama-3.1-8b-instant\"\n",
    "    ):\n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant that solves math problems.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            model=model,\n",
    "            temperature=0.3, ### 수정해도 됩니다!\n",
    "            stream=False\n",
    "        )\n",
    "        return chat_completion.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"API call error: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef65ad3",
   "metadata": {},
   "source": [
    "#### 응답 잘 나오는지 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a37fad9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world! I'm here to help with any math problems you might have. What's on your mind? Do you have a specific problem you'd like me to solve, or would you like some help with a particular math concept?\n"
     ]
    }
   ],
   "source": [
    "response = generate_response_using_Llama(\n",
    "    prompt=\"Hello world!\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988803ae",
   "metadata": {},
   "source": [
    "#### GSM8K 데이터셋 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbd177eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Question]\n",
      "Janet’s ducks lay 16 eggs per day\n",
      " She eats three for breakfast every morning and bakes muffins for her friends every day with four\n",
      " She sells the remainder at the farmers' market daily for $2 per fresh duck egg\n",
      " How much in dollars does she make every day at the farmers' market?\n",
      "====================================================================================================\n",
      "[Answer]\n",
      "Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\n",
      "She makes 9 * 2 = $<<9*2=18>>18 every day at the farmer’s market.\n",
      "#### 18\n"
     ]
    }
   ],
   "source": [
    "print(\"[Question]\")\n",
    "for l in gsm8k_test['question'][0].split(\".\"):\n",
    "    print(l)\n",
    "print(\"=\"*100)\n",
    "print(\"[Answer]\")\n",
    "print(gsm8k_test['answer'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaabe66c",
   "metadata": {},
   "source": [
    "#### Util 함수들\n",
    "- extract_final_answer: LLM의 응답을 parse하여 최종 결과만 추출 (정답과 비교하기 위해)\n",
    "- run_benchmark_test: 벤치마크 테스트\n",
    "- save_final_result: 결과물 제출을 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40c10811",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 수정해도 됩니다!\n",
    "def extract_final_answer(response: str):\n",
    "    regex = r\"(?:Answer:|Model response:)\\s*\\$?([0-9,]+)\\b|([0-9,]+)\\s*(meters|cups|miles|minutes)\"\n",
    "    matches = re.finditer(regex, response, re.MULTILINE)\n",
    "    results = [match.group(1) if match.group(1) else match.group(2).replace(\",\", \"\") for match in matches]\n",
    "\n",
    "    if len(results) == 0:\n",
    "        additional_regex = r\"\\$?([0-9,]+)\"\n",
    "        additional_matches = re.finditer(additional_regex, response, re.MULTILINE)\n",
    "        results.extend([match.group(1).replace(\",\", \"\") for match in additional_matches])\n",
    "\n",
    "    return results[-1] if results else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e3a05ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 수정해도 됩니다!\n",
    "def run_benchmark_test(\n",
    "        dataset,\n",
    "        prompt: str,\n",
    "        model: str = \"llama-3.1-8b-instant\",\n",
    "        num_samples: int = 50,\n",
    "        VERBOSE: bool = False\n",
    "    ):\n",
    "    correct = 0\n",
    "    total   = 0\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(min(num_samples, len(dataset)))):\n",
    "        question = dataset[i][\"question\"]\n",
    "        correct_answer = float(re.findall(r'\\d+(?:\\.\\d+)?', dataset[i][\"answer\"].split('####')[-1])[0])\n",
    "\n",
    "        response = generate_response_using_Llama(\n",
    "            prompt=prompt.format(question=question),\n",
    "            model=model\n",
    "        )\n",
    "\n",
    "        if response:\n",
    "            if VERBOSE:\n",
    "                print(\"=\"*50)\n",
    "                print(response)\n",
    "                print(\"=\"*50)\n",
    "            predicted_answer_str = extract_final_answer(response)\n",
    "\n",
    "            # 수정됨\n",
    "            if predicted_answer_str:\n",
    "                try:\n",
    "                    predicted_answer = float(predicted_answer_str.replace(\",\", \"\"))\n",
    "                except ValueError:\n",
    "                    if VERBOSE:\n",
    "                        print(f\"Warning: Could not parse answer '{predicted_answer}'\")\n",
    "                    predicted_answer = None\n",
    "\n",
    "            is_correct = False\n",
    "            if predicted_answer is not None:\n",
    "                diff = abs(predicted_answer - correct_answer)\n",
    "                is_correct = diff < 1e-5\n",
    "\n",
    "            if is_correct:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "            results.append({\n",
    "                'question': question,\n",
    "                'correct_answer': correct_answer,\n",
    "                'predicted_answer': predicted_answer,\n",
    "                'response': response,\n",
    "                'correct': is_correct\n",
    "            })\n",
    "\n",
    "            if (i + 1) % 5 == 0:\n",
    "                current_acc = correct/total if total > 0 else 0\n",
    "                print(f\"Progress: [{i+1}/{num_samples}]\")\n",
    "                print(f\"Current Acc.: [{current_acc:.2%}]\")\n",
    "\n",
    "    return results, correct/total if total > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e63f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_final_result(results: List[Dict[str, Any]], accuracy: float, filename: str) -> None:\n",
    "    result_str = f\"====== ACCURACY: {accuracy} ======\\n\\n\"\n",
    "    result_str += f\"[Details]\\n\"\n",
    "    \n",
    "    for idx, result in enumerate(results):\n",
    "        result_str += f\"Question {idx+1}: {result['question']}\\n\"\n",
    "        result_str += f\"Correct Answer: {result['correct_answer']}\\n\"\n",
    "        result_str += f\"Predicted Answer: {result['predicted_answer']}\\n\"\n",
    "        result_str += f\"Correct: {result['correct']}\\n\\n\"\n",
    "    \n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(result_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c498f9ed",
   "metadata": {},
   "source": [
    "#### Direct prompting with few-shot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f430083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_direct_prompt(num_examples: int = 3) -> str:\n",
    "    train_dataset = gsm8k_train\n",
    "\n",
    "    sampled_indices = random.sample(\n",
    "        [i for i in range(len(train_dataset['question']))],\n",
    "        num_examples\n",
    "    )\n",
    "\n",
    "    prompt = \"Instruction:\\nSolve the following mathematical question and generate ONLY the answer after a tag, 'Answer:' without any rationale.\\n\"\n",
    "\n",
    "    for i in range(num_examples):\n",
    "        cur_question = train_dataset['question'][i]\n",
    "        cur_answer = train_dataset['answer'][i].split(\"####\")[-1].strip()\n",
    "\n",
    "        prompt += f\"\\n[Example {i+1}]\\n\"\n",
    "        prompt += f\"Question:\\n{cur_question}\\n\"\n",
    "        prompt += f\"Answer:{cur_answer}\\n\"\n",
    "\n",
    "    prompt += \"\\nQuestion:\\n{question}\\nAnswer:\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68a2b484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:02<00:02,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/10]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/10]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### 어떤 방식으로 저장되는지 확인해보세요!\n",
    "PROMPT = construct_direct_prompt(3)\n",
    "VERBOSE = False\n",
    "\n",
    "results, accuracy = run_benchmark_test(\n",
    "    dataset=gsm8k_test,\n",
    "    prompt=PROMPT,\n",
    "    VERBOSE=VERBOSE,\n",
    "    num_samples=10\n",
    ")\n",
    "save_final_result(results, accuracy, \"example.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41874896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Direct Prompting Benchmarks ---\n",
      "Processing Direct Prompting 0-shot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:01<00:15,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:03<00:14,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:05<00:12,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [73.33%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:07<00:10,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:09<00:09,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [84.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [00:13<00:25,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [83.33%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [00:24<00:31,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [85.71%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [00:43<00:34,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [85.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [00:53<00:11,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [84.44%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:06<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [86.00%]\n",
      "Processing Direct Prompting 3-shot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:17<02:58,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [100.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:36<02:35,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:55<02:10,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [01:13<01:48,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [01:31<01:30,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [01:49<01:11,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [83.33%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [02:07<00:53,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [85.71%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [02:25<00:36,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [87.50%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [02:45<00:19,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [84.44%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:06<00:00,  3.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [84.00%]\n",
      "Processing Direct Prompting 5-shot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:30<04:38,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:54<03:26,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [01:27<03:37,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [66.67%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [01:58<03:32,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [02:37<02:40,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [68.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [03:00<01:37,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [03:22<01:09,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [74.29%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [03:53<01:07,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [77.50%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [04:17<00:25,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [75.56%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:42<00:00,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [76.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: 0 shot, 3 shot, 5 shot direct prompting을 통해 벤치마크 테스트를 한 후, 각각 direct_prompting_{shot: int}.txt로 저장해주세요!\n",
    "# 예시: shot이 5인 경우 direct_prompting_5.txt\n",
    "# 항상 num_samples=50 입니다!\n",
    "\n",
    "shots = [0, 3, 5]\n",
    "    \n",
    "print(\"\\n--- Starting Direct Prompting Benchmarks ---\")\n",
    "for shot in shots:\n",
    "    filename = f\"direct_prompting_{shot}.txt\"\n",
    "    print(f\"Processing Direct Prompting {shot}-shot...\")\n",
    "    results, acc = run_benchmark_test(\n",
    "        dataset=gsm8k_test,\n",
    "        prompt=construct_direct_prompt(shot),\n",
    "        VERBOSE=False,\n",
    "        num_samples=50\n",
    "    )\n",
    "    save_final_result(results, acc, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fd21d1",
   "metadata": {},
   "source": [
    "### Chain-of-Thought prompting with few-shot example\n",
    "```text\n",
    "[Question]\n",
    "Janet’s ducks lay 16 eggs per day\n",
    " She eats three for breakfast every morning and bakes muffins for her friends every day with four\n",
    " She sells the remainder at the farmers' market daily for $2 per fresh duck egg\n",
    " How much in dollars does she make every day at the farmers' market?\n",
    "====================================================================================================\n",
    "[Answer]\n",
    "Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\n",
    "She makes 9 * 2 = $<<9*2=18>>18 every day at the farmer’s market.\n",
    "#### 18\n",
    "```\n",
    "\n",
    "[Answer] 아래의 정답을 도출하는 과정을 예시로 달아주면 CoT의 few shot이 되겠죠?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73a989e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_CoT_prompt(num_examples: int = 3) -> str:\n",
    "    train_dataset = gsm8k_train\n",
    "\n",
    "    sampled_indices = random.sample(\n",
    "        [i for i in range(len(train_dataset['question']))],\n",
    "        num_examples\n",
    "    )\n",
    "    # CoT prompt instruction\n",
    "    prompt = \"Instruction:\\nSolve the following mathematical problems step by step. Show your reasoning and put the final answer after '####'.\\n\"\n",
    "\n",
    "    for i, idx in enumerate(sampled_indices):\n",
    "        cur_question = train_dataset['question'][idx]\n",
    "        cur_answer = train_dataset['answer'][idx] # Take the FULL answer including reasoning\n",
    "\n",
    "        prompt += f\"\\n[Example {i+1}]\\n\"\n",
    "        prompt += f\"Question:\\n{cur_question}\\n\"\n",
    "        prompt += f\"Answer:\\n{cur_answer}\\n\"\n",
    "\n",
    "    prompt += \"\\nQuestion:\\n{question}\\nAnswer:\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c510586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting CoT Prompting Benchmarks ---\n",
      "Processing CoT Prompting 0-shot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:02<00:21,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [100.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:04<00:20,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:07<00:17,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [73.33%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:13<00:44,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:31<00:58,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [68.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [00:43<00:47,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [00:52<00:27,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [74.29%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [01:03<00:22,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [01:18<00:16,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [68.89%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:29<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [72.00%]\n",
      "Processing CoT Prompting 3-shot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:38<05:37,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [01:17<05:12,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [01:56<04:32,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [02:29<03:31,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [03:07<03:05,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [76.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [03:40<02:01,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [76.67%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [04:14<01:43,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [04:55<01:14,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [77.50%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [05:30<00:37,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [77.78%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:09<00:00,  7.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [80.00%]\n",
      "Processing CoT Prompting 5-shot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:49<07:38, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [100.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [01:49<08:05, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [02:35<05:54, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [03:27<05:09, 10.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [75.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [04:17<04:07,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [76.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [05:09<03:26, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [76.67%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [05:59<02:28,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [06:50<01:43, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [75.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [07:43<00:53, 10.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [75.56%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [08:34<00:00, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [76.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: 0 shot, 3 shot, 5 shot CoT prompting을 통해 벤치마크 테스트를 한 후, 각각 CoT_prompting_{shot: int}.txt로 저장해주세요!\n",
    "# 예시: shot이 5인 경우 CoT_prompting_5.txt\n",
    "# 항상 num_samples=50 입니다!\n",
    "\n",
    "print(\"\\n--- Starting CoT Prompting Benchmarks ---\")\n",
    "for shot in shots:\n",
    "    filename = f\"CoT_prompting_{shot}.txt\"\n",
    "    print(f\"Processing CoT Prompting {shot}-shot...\")\n",
    "    results, acc = run_benchmark_test(\n",
    "        dataset=gsm8k_test,\n",
    "        prompt=construct_CoT_prompt(shot),\n",
    "        VERBOSE=False,\n",
    "        num_samples=50\n",
    "    )\n",
    "    save_final_result(results, acc, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c45b54",
   "metadata": {},
   "source": [
    "### Construct your prompt!!\n",
    "\n",
    "목표: 본인만의 프롬프트를 통해 정답률을 더 끌어올려보기!\n",
    "- gsm8k의 train 데이터셋에서 예시를 가져온 다음 (자유롭게!)\n",
    "- 그 예시들에 대한 풀이 과정을 만들어주세요!\n",
    "- 모든 것들이 자유입니다! Direct Prompting, CoT Prompting을 한 결과보다 정답률만 높으면 돼요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09062c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 자유롭게 수정해도 됩니다! 완전히 새로 함수를 만들어도 돼요.\n",
    "def construct_my_prompt(num_examples: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    [구조적 추론 (Structured Reasoning) 프롬프트 생성 함수]\n",
    "    \n",
    "    전략의 의도:\n",
    "    1. 목표 정의 (Goal Definition): 연산을 시작하기 전에 문제의 핵심 요구사항을 먼저 파악하게 하여, 엉뚱한 방향으로 풀이가 진행되는 것을 방지합니다.\n",
    "    2. 구조화된 출력 (Structured Output): [Goal] -> [Solution] -> [Answer]라는 명확한 헤더를 제시하여, 모델이 사고 과정을 체계적으로 정리하고, 답변 파싱(Parsing)의 정확도를 높입니다.\n",
    "    3. 논리적 일관성 (Consistency): 계획과 실행 단계를(혹은 목표와 풀이를) 분리함으로써, 초기 단계의 잘못된 가정에 매몰되지 않고 논리적인 흐름을 유지할 가능성을 높입니다.\n",
    "    \"\"\"\n",
    "    train_dataset = gsm8k_train\n",
    "    \n",
    "    # Use a fixed seed or consistent sampling if needed\n",
    "    indices = list(range(len(train_dataset['question'])))\n",
    "    sampled_indices = random.sample(indices, num_examples)\n",
    "\n",
    "    # Improved Instruction: clear separation of Logic (Plan) vs Math (Work)\n",
    "    prompt = (\n",
    "        \"Instruction:\\n\"\n",
    "        \"You are a math expert. Solve the problem by following this strict format:\\n\"\n",
    "        \"1. [Plan]: Break down the problem into logical steps without calculating yet.\\n\"\n",
    "        \"2. [Work]: Perform the calculations step-by-step based on your plan.\\n\"\n",
    "        \"3. [Check]: Quickly verify if your answer makes sense (e.g., estimation or reverse check).\\n\"\n",
    "        \"4. [Answer]: State the final number after '####'.\\n\"\n",
    "    )\n",
    "\n",
    "    for i, idx in enumerate(sampled_indices):\n",
    "        cur_question = train_dataset['question'][idx]\n",
    "        cur_answer = train_dataset['answer'][idx] \n",
    "        \n",
    "        prompt += f\"\\n[Example {i+1}]\\n\"\n",
    "        prompt += f\"Question:\\n{cur_question}\\n\"\n",
    "        prompt += f\"[Plan]: Identify the operations needed to solve for the target value.\\n\"\n",
    "        prompt += f\"[Work]:\\n{cur_answer}\\n\"\n",
    "        prompt += f\"[Check]: The steps follow logically.\\n\"\n",
    "\n",
    "    prompt += \"\\nQuestion:\\n{question}\\n\"\n",
    "    prompt += \"[Plan]:\" # Trigger the model to start planning\n",
    "\n",
    "    return prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ac2b0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting My Custom Prompting Benchmarks ---\n",
      "Processing My Custom Prompting 0-shot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:03<00:30,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:06<00:25,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:09<00:17,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [46.67%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:23<01:14,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [50.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:36<01:05,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [48.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [00:49<00:51,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [40.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [01:02<00:39,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [34.29%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [01:16<00:28,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [32.50%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [01:31<00:14,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [33.33%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:46<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [34.00%]\n",
      "Processing My Custom Prompting 3-shot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:44<06:52,  9.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [01:31<06:15,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [02:18<05:21,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [66.67%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [03:04<04:36,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [03:49<03:42,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [64.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [04:35<03:04,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [05:10<01:41,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [65.71%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [05:50<01:24,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [06:34<00:45,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:12<00:00,  8.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [60.00%]\n",
      "Processing My Custom Prompting 5-shot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:51<07:44, 10.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [01:40<06:40, 10.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [02:30<03:35,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499999, Requested 920. Please try again in 2m38.8032s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499998, Requested 961. Please try again in 2m45.7152s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [02:31<02:28,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499997, Requested 921. Please try again in 2m38.6304s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [02:31<01:10,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499996, Requested 924. Please try again in 2m38.976s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499995, Requested 900. Please try again in 2m34.656s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [02:31<00:49,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499994, Requested 935. Please try again in 2m40.5312s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [02:32<00:25,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499993, Requested 931. Please try again in 2m39.6672s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499992, Requested 915. Please try again in 2m36.7296s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [02:32<00:18,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499991, Requested 926. Please try again in 2m38.4576s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [02:32<00:10,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499990, Requested 909. Please try again in 2m35.3472s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499989, Requested 907. Please try again in 2m34.8288s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [02:32<00:06,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499988, Requested 935. Please try again in 2m39.494399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499987, Requested 935. Please try again in 2m39.3216s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [02:33<00:04,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499986, Requested 927. Please try again in 2m37.7664s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499985, Requested 918. Please try again in 2m36.0384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [02:33<00:03,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499984, Requested 939. Please try again in 2m39.494399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [02:33<00:03,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499983, Requested 906. Please try again in 2m33.6192s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499982, Requested 931. Please try again in 2m37.7664s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [02:33<00:03,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499981, Requested 911. Please try again in 2m34.1376s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [02:34<00:02,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499980, Requested 899. Please try again in 2m31.8912s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499979, Requested 911. Please try again in 2m33.792s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [02:34<00:02,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499978, Requested 919. Please try again in 2m35.0016s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499977, Requested 913. Please try again in 2m33.792s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [02:34<00:01,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499976, Requested 931. Please try again in 2m36.7296s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [02:35<00:01,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499975, Requested 914. Please try again in 2m33.6192s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499974, Requested 944. Please try again in 2m38.6304s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [02:35<00:01,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499973, Requested 915. Please try again in 2m33.4464s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [02:35<00:02,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499970, Requested 995. Please try again in 2m46.752s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [02:36<00:01,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499969, Requested 952. Please try again in 2m39.1488s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499968, Requested 924. Please try again in 2m34.1376s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [02:36<00:00,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499967, Requested 943. Please try again in 2m37.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499966, Requested 965. Please try again in 2m40.8768s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [02:36<00:00,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499965, Requested 961. Please try again in 2m40.0128s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499964, Requested 917. Please try again in 2m32.2368s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:37<00:00,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499963, Requested 908. Please try again in 2m30.5088s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "API call error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kges0kwrf5s8hjs9tz93s5w8` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499962, Requested 913. Please try again in 2m31.2s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: 만든 0 shot, 3 shot, 5 shot example과 프롬프트를 통해 벤치마크 테스트를 한 후, 각각 My_prompting_{shot: int}.txt로 저장해주세요!\n",
    "# 예시: shot이 5인 경우 My_prompting_5.txt\n",
    "# 항상 num_samples=50 입니다!\n",
    "\n",
    "print(\"\\n--- Starting My Custom Prompting Benchmarks ---\")\n",
    "for shot in shots:\n",
    "    filename = f\"My_prompting_new_{shot}.txt\"\n",
    "    print(f\"Processing My Custom Prompting {shot}-shot...\")\n",
    "    results, acc = run_benchmark_test(\n",
    "        dataset=gsm8k_test,\n",
    "        prompt=construct_my_prompt(shot),\n",
    "        VERBOSE=False,\n",
    "        num_samples=50\n",
    "    )\n",
    "    save_final_result(results, acc, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd837d7",
   "metadata": {},
   "source": [
    "### 보고서 작성하기\n",
    "#### 아래의 내용이 포함되면 됩니다!\n",
    "\n",
    "1. Direct Prompting, CoT Prompting, My Prompting을 0 shot, 3 shot, 5 shot 정답률을 표로 보여주세요!\n",
    "2. CoT Prompting이 Direct Prompting에 비해 왜 좋을 수 있는지에 대해서 서술해주세요!\n",
    "3. 본인이 작성한 프롬프트 기법이 CoT에 비해서 왜 더 좋을 수 있는지에 대해서 설명해주세요!\n",
    "4. 최종적으로, `PROMPTING.md`에 보고서를 작성해주세요!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
